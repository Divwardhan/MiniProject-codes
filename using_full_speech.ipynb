{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2399dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe551663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('compiled_speeches_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16cf67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     time                                            speaker  \\\n",
       "0  2019-11-18  11:00AM  ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...   \n",
       "1  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "2  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "3  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "4  2019-11-18  11:00AM                        ‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)   \n",
       "\n",
       "                                              speech  \n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...  \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...  \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...  \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773b1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove speeches shorter than ~8 words\n",
    "df = df[df['speech'].str.split().str.len() > 8]\n",
    "\n",
    "# Alternatively, based on character length\n",
    "df = df[df['speech'].str.len() > 40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c223338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     time                                            speaker  \\\n",
       "0  2019-11-18  11:00AM  ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...   \n",
       "1  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "2  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "3  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "4  2019-11-18  11:00AM                        ‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)   \n",
       "\n",
       "                                              speech  \n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...  \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...  \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...  \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9edad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14939, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec82397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á‡§ü‡§≤‡•Ä ‡§ú‡•Ä, ‡§∏‡•Å‡§ñ‡§¶‡•á‡§µ ‡§∏‡§ø‡§Ç‡§π ‡§≤‡§ø‡§¨‡•ç‡§∞‡§æ ‡§ú‡•Ä, ‡§∞‡§æ‡§Æ ‡§ú‡•á‡§†‡§Æ‡§≤‡§æ‡§®‡•Ä ‡§ú‡•Ä, ‡§ó‡•Å‡§∞‡•Å‡§¶‡§æ‡§∏ ‡§¶‡§æ‡§∏ ‡§ó‡•Å‡§™‡•ç‡§§‡§æ ‡§ú‡•Ä, ‡§ú‡•ã ‡§ï‡§ø ‡§Ö‡§™‡§®‡•á ‡§π‡§æ‡§â‡§∏ ‡§ï‡•á ‡§Æ‡•á‡§Æ‡•ç‡§¨‡§∞‡•ç‡§∏ ‡§•‡•á ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•Ä AVS ‡§ó‡§à ‡§π‡•à ‡§ï‡§≤‡•Ä, ‡§Æ‡•à‡§Ç ‡§¶‡•á‡§§‡§æ ‡§π‡•Ç‡§Å ‡§Ü‡§∞‡§™‡•Ä‡§Ü‡§à ‡§ï‡•Ä ‡§§‡§∞‡§´ ‡§∏‡•á ‡§á‡§®‡§ï‡•ã ‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡§æ‡§Ç‡§ú‡§≤‡§ø ‡§Ö‡§™‡§®‡•á ‡§∏‡§Æ‡§æ‡§ú ‡§î‡§∞ ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§®‡§ï‡§æ ‡§Ø‡•ã‡§ó‡§¶‡§æ‡§® ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä ‡§¨‡§ø‡§π‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§•‡•á ‡§î‡§∞ ‡§â‡§®‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡§Æ ‡§∏‡•Å‡§®‡§§‡•á ‡§•‡•á ‡§ï‡§ø ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø ‡§â‡§®‡§ï‡•á ‡§Æ‡§® ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡•Ä ‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡§æ ‡§•‡•Ä‡•§ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§¶‡§ø‡§≤‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§∏‡§Ç‡§ò‡§∞‡•ç‡§∑ ‡§≠‡•Ä ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á‡§ü‡§≤‡•Ä ‡§ú‡•Ä ‡§ï‡•ã'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speech'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a074d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # normalize whitespace\n",
    "    text = re.sub(r'[\"‚Äú‚Äù]+', '', text)  # remove stray quotes\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)  # remove content in parentheses\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['clean_speech'] = df['speech'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f4a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "# df[\"embedding\"] = df[\"clean_speech\"].apply(lambda x: model.encode(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3b9a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>clean_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     time                                            speaker  \\\n",
       "0  2019-11-18  11:00AM  ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...   \n",
       "1  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "2  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "3  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "4  2019-11-18  11:00AM                        ‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)   \n",
       "\n",
       "                                              speech  \\\n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...   \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...   \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...   \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...   \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...   \n",
       "\n",
       "                                        clean_speech  \n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...  \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...  \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...  \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['clean_speech'].str.split().apply(len) > 5]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e7d3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import pandas as pd\n",
    "# # Assuming df[\"embedding\"] contains list/array embeddings\n",
    "# embeddings = np.stack(df[\"embedding\"].values) \n",
    "# # Compute full cosine similarity matrix\n",
    "# similarity_matrix = cosine_similarity(embeddings)\n",
    "# # Convert to DataFrame for easier handling (optional)\n",
    "# similarity_df = pd.DataFrame(similarity_matrix, index=df.index, columns=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "179c7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7bda126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(similarity_df, cmap=\"viridis\")  # or \"coolwarm\", \"magma\"\n",
    "# plt.title(\"Cosine Similarity Between Speeches\")\n",
    "# plt.xlabel(\"Speech Index\")\n",
    "# plt.ylabel(\"Speech Index\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48d46afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.clustermap(similarity_df, cmap=\"viridis\", figsize=(12, 12))\n",
    "# plt.title(\"Clustered Cosine Similarity of Speeches\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e33df7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>clean_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     time                                            speaker  \\\n",
       "0  2019-11-18  11:00AM  ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...   \n",
       "1  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "2  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "3  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "4  2019-11-18  11:00AM                        ‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)   \n",
       "\n",
       "                                              speech  \\\n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...   \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...   \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...   \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...   \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...   \n",
       "\n",
       "                                        clean_speech  \n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...  \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...  \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...  \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d5405e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Clustermap\n",
    "# sns.clustermap(\n",
    "#     similarity_df,          # your cosine similarity matrix\n",
    "#     cmap=\"viridis\",         # color map (you can try \"coolwarm\" or \"magma\")\n",
    "#     figsize=(12, 12),       # adjust size\n",
    "#     metric=\"euclidean\",     # distance metric for clustering\n",
    "#     method=\"average\"        # linkage method\n",
    "# )\n",
    "\n",
    "# plt.suptitle(\"Clustered Cosine Similarity of Speeches\", y=1.02)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0abd80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0162af6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>clean_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "      <td>‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "      <td>‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "      <td>‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "      <td>‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "      <td>‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     time                                            speaker  \\\n",
       "0  2019-11-18  11:00AM  ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡§ø‡§§‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡§æ‡§≤‡§Ø A ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡§Ç...   \n",
       "1  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "2  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "3  2019-11-18  11:00AM                                 ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ‡§¶‡§æ‡§∏ ‡§Ö‡§†‡§æ‡§µ‡§≤‡•á   \n",
       "4  2019-11-18  11:00AM                        ‡§∂‡•ç‡§∞‡•Ä ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ (‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞)   \n",
       "\n",
       "                                              speech  \\\n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...   \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...   \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...   \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...   \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...   \n",
       "\n",
       "                                        clean_speech  \n",
       "0  ‡§ö‡•á‡§Ø‡§∞‡§Æ‡•à‡§® ‡§∏‡§∞, ‡§°‡§æ. ‡§ú‡§ó‡§®‡•ç‡§®‡§æ‡§• ‡§Æ‡§ø‡§∂‡•ç‡§∞ ‡§ú‡•Ä, ‡§∂‡•ç‡§∞‡•Ä ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  \n",
       "1  ‡§Æ‡§§‡§≤‡§¨, ‡§µ‡§ï‡•ç ‡§§ ‡§™‡§∞ ‡§ú‡§∞‡•Ç‡§∞ ‡§π‡•à ‡§Æ‡•á‡§∞‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Æ‡•á‡§∞‡•á ...  \n",
       "2  ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á...  \n",
       "3  ‡§Æ‡•à‡§Ç ‡§á‡§® ‡§∏‡§≠‡•Ä ‡§®‡•á‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§∞‡§ø‡§™‡§¨‡•ç‡§≤‡§ø‡§ï‡§® ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä ‡§ë‡§´ ...  \n",
       "4  ‡§∏‡§∞, ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§™‡§π‡§≤‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§Ø‡§æ ‡§•‡§æ, ‡§§‡§¨ ‡§Ö‡§∞‡•Å‡§£ ‡§ú‡•á...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e93ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from sklearn.preprocessing import normalize\n",
    "# from sklearn.metrics.pairwise import cosine_similarity # <-- New Import for similarity matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# X_embeddings_raw = np.stack(df['embedding'].values) # Original embeddings\n",
    "\n",
    "# # ----------------------------------------------------\n",
    "# # üåü STEP A: COMPUTE COSINE SIMILARITY MATRIX üåü\n",
    "# # This is the N x N matrix for your verification.\n",
    "# # ----------------------------------------------------\n",
    "# cosine_similarity_matrix = cosine_similarity(X_embeddings_raw)\n",
    "\n",
    "# # Store the N x N matrix in a DataFrame for clear verification\n",
    "# similarity_df_for_verification = pd.DataFrame(\n",
    "#     cosine_similarity_matrix,\n",
    "#     index=df.index,\n",
    "#     columns=df.index\n",
    "# )\n",
    "# print(\"--- Computed Cosine Similarity Matrix (similarity_df_for_verification) ---\")\n",
    "# print(similarity_df_for_verification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b9ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ----------------------------------------------------\n",
    "# # üåü STEP B: K-MEANS CLUSTERING (on Normalized Embeddings) üåü\n",
    "# # ----------------------------------------------------\n",
    "\n",
    "# # Normalize the embeddings for effective cosine K-Means\n",
    "# X_embeddings_normalized = normalize(X_embeddings_raw, norm='l2', axis=1)\n",
    "\n",
    "# # Define the range of K values\n",
    "# k_range = range(5, 60) \n",
    "\n",
    "# # Lists to store the evaluation metrics\n",
    "# inertia_values = []\n",
    "# silhouette_scores = []\n",
    "# results = {}\n",
    "\n",
    "# print(f\"\\nStarting K-Means evaluation (using Cosine logic) for K = {k_range.start} to {k_range.stop - 1}...\")\n",
    "\n",
    "# for k in k_range:\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "#     kmeans.fit(X_embeddings_normalized)\n",
    "\n",
    "#     inertia_values.append(kmeans.inertia_)\n",
    "    \n",
    "#     if k >= 2:\n",
    "#         # Use 'cosine' metric for the silhouette score calculation\n",
    "#         score = silhouette_score(X_embeddings_normalized, kmeans.labels_, metric='cosine') \n",
    "#         silhouette_scores.append(score)\n",
    "#         results[k] = {'Inertia': kmeans.inertia_, 'Silhouette Score (Cosine)': score, 'Labels': kmeans.labels_}\n",
    "\n",
    "# print(\"Evaluation Complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24776682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 2. SELECT OPTIMAL K ---\n",
    "\n",
    "# best_k_silhouette = max(results, key=lambda k: results[k]['Silhouette Score (Cosine)'])\n",
    "\n",
    "# print(f\"\\nRecommended K based on maximum Cosine Silhouette Score: K = {best_k_silhouette}\")\n",
    "\n",
    "# # --- 3. FINAL CLUSTERING AND ASSIGNMENT ---\n",
    "\n",
    "# K_FINAL = best_k_silhouette \n",
    "# print(f\"\\nAssigning final cluster labels with K={K_FINAL}...\")\n",
    "\n",
    "# # Add the final cluster labels for the optimal K\n",
    "# df['cluster_label'] = results[K_FINAL]['Labels']\n",
    "\n",
    "# print(f\"Cluster labels added to the DataFrame. First 5 rows:\")\n",
    "# print(df[['clean_speech', 'cluster_label']].head())\n",
    "\n",
    "# # --- 4. PLOTS ---\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# # Plot 1: Elbow Method\n",
    "# axes[0].plot(k_range, inertia_values, marker='o', linestyle='--')\n",
    "# axes[0].set_title('Elbow Method (Inertia on Normalized Embeddings)')\n",
    "# axes[0].set_xlabel('Number of Clusters (K)')\n",
    "# axes[0].set_ylabel('Inertia (WC-SS)')\n",
    "# axes[0].grid(True)\n",
    "# axes[0].axvline(x=best_k_silhouette, color='r', linestyle=':', label=f'Best K ({best_k_silhouette})')\n",
    "# axes[0].legend()\n",
    "\n",
    "\n",
    "# # Plot 2: Silhouette Score (Cosine Metric)\n",
    "# axes[1].plot(k_range, silhouette_scores, marker='o', linestyle='--')\n",
    "# axes[1].set_title('Silhouette Score (Using Cosine Metric)')\n",
    "# axes[1].set_xlabel('Number of Clusters (K)')\n",
    "# axes[1].set_ylabel('Average Cosine Silhouette Score')\n",
    "# axes[1].grid(True)\n",
    "# axes[1].axvline(x=best_k_silhouette, color='r', linestyle='-', label=f'Best K ({best_k_silhouette})')\n",
    "# axes[1].legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffdf403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------------------------------\n",
    "# # üåü STEP C: CLUSTER VISUALIZATION (2D & 3D) üåü\n",
    "# # ----------------------------------------------------\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (needed for 3D plotting)\n",
    "\n",
    "# # === 1Ô∏è‚É£ PCA for fast dimensionality reduction ===\n",
    "# print(\"\\nPerforming PCA dimensionality reduction for visualization...\")\n",
    "# pca_2d = PCA(n_components=2, random_state=42)\n",
    "# pca_3d = PCA(n_components=3, random_state=42)\n",
    "\n",
    "# X_pca_2d = pca_2d.fit_transform(X_embeddings_normalized)\n",
    "# X_pca_3d = pca_3d.fit_transform(X_embeddings_normalized)\n",
    "\n",
    "# # === 2Ô∏è‚É£ 2D Visualization (PCA) ===\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# scatter = plt.scatter(\n",
    "#     X_pca_2d[:, 0], X_pca_2d[:, 1],\n",
    "#     c=df['cluster_label'], cmap='tab10', s=40, alpha=0.8\n",
    "# )\n",
    "# plt.title(f'2D PCA Visualization (K={K_FINAL})')\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # === 3Ô∏è‚É£ 3D Visualization (PCA) ===\n",
    "# fig = plt.figure(figsize=(10, 7))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# sc = ax.scatter(\n",
    "#     X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],\n",
    "#     c=df['cluster_label'], cmap='tab10', s=40, alpha=0.8\n",
    "# )\n",
    "# ax.set_title(f'3D PCA Visualization (K={K_FINAL})')\n",
    "# ax.set_xlabel('PC 1')\n",
    "# ax.set_ylabel('PC 2')\n",
    "# ax.set_zlabel('PC 3')\n",
    "# plt.legend(*sc.legend_elements(), title=\"Clusters\")\n",
    "# plt.show()\n",
    "\n",
    "# # ----------------------------------------------------\n",
    "# # (Optional) Use t-SNE for more nonlinear structure visualization\n",
    "# # ----------------------------------------------------\n",
    "# print(\"\\nRunning t-SNE for more detailed cluster visualization (may take time)...\")\n",
    "# from sklearn.manifold import TSNE\n",
    "# import sklearn\n",
    "\n",
    "# # detect sklearn version and use appropriate param\n",
    "# tsne_kwargs = dict(\n",
    "#     n_components=2,\n",
    "#     perplexity=30,\n",
    "#     metric='cosine',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Handle compatibility for n_iter vs max_iter\n",
    "# if sklearn.__version__ >= \"1.2\":\n",
    "#     tsne_kwargs['max_iter'] = 1000\n",
    "# else:\n",
    "#     tsne_kwargs['n_iter'] = 1000\n",
    "\n",
    "# tsne_2d = TSNE(**tsne_kwargs)\n",
    "\n",
    "# X_tsne_2d = tsne_2d.fit_transform(X_embeddings_normalized)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# scatter_tsne = plt.scatter(\n",
    "#     X_tsne_2d[:, 0], X_tsne_2d[:, 1],\n",
    "#     c=df['cluster_label'], cmap='tab10', s=40, alpha=0.8\n",
    "# )\n",
    "# plt.title(f't-SNE (2D, Cosine Metric) Visualization (K={K_FINAL})')\n",
    "# plt.xlabel('t-SNE Dim 1')\n",
    "# plt.ylabel('t-SNE Dim 2')\n",
    "# plt.legend(*scatter_tsne.legend_elements(), title=\"Clusters\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fcfe4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = re.sub(r'\\n+', ' ', text)            # remove newlines\n",
    "#     text = re.sub(r'\\s+', ' ', text)            # normalize spaces\n",
    "#     text = re.sub(r'\\([^)]*\\)', '', text)       # remove text in parentheses\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)         # remove punctuation\n",
    "#     return text.lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ab5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=df[df['cluster_label']==38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84d8a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b87194db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Speeches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [01:44<00:00,  1.05s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_highlight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# assign to first 100 rows only\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic_highlight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m topics\n\u001b[0;32m     55\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_highlighted_speeches.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Done. File saved as topic_highlighted_speeches.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1942\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\Vishal\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\indexing.py:1998\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(info_axis):\n\u001b[0;32m   1994\u001b[0m         \u001b[38;5;66;03m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[0;32m   1995\u001b[0m         \u001b[38;5;66;03m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[0;32m   1996\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[38;5;241m0\u001b[39m]), value[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 1998\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1999\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2001\u001b[0m     )\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m   2004\u001b[0m     \u001b[38;5;66;03m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load CSV\n",
    "# df = pd.read_csv(\"compiled_speeches.csv\")\n",
    "\n",
    "BASE_PROMPT = \"\"\"\n",
    "You are an expert Indian Parliamentary proceedings topic classifier. \n",
    "Your job is NOT to summarize the speech. Your job is to identify what specific policy / issue / subject matter is being talked about in ONE short crisp category.\n",
    "\n",
    "Rules:\n",
    "- Return EXACTLY 1 topic phrase for each speech (7-12 words max)\n",
    "- If the speech is just procedural / rhetorical / filler / greeting ‚Üí return \"irrelevant\"\n",
    "- Hindi, English, Hinglish all supported.\n",
    "- Make topics focused on meaning, not literal words.\n",
    "\n",
    "FORMAT:\n",
    "Topic: <short topic phrase>\n",
    "\n",
    "### Example:\n",
    "Speech Input:\n",
    "\"National Commission for Religious and Linguistic Minorities‚Ä¶ Dalit Christians and Dalit Muslims reservations extension‚Ä¶\"\n",
    "\n",
    "Output:\n",
    "Topic: Reservation for Dalit Christians and Dalit Muslims\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "topics = []\n",
    "\n",
    "for speech in tqdm(df[\"speech\"][:100], desc=\"Processing Speeches\"):\n",
    "    prompt = BASE_PROMPT + f\"\\n\\nSpeech Input:\\n{speech}\\n\\nOutput:\\n\"\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"llama3.2\"],  # using phi model here\n",
    "            input=prompt,\n",
    "            text=True,  # ensures stdout is str, not bytes\n",
    "            capture_output=True\n",
    "        )\n",
    "\n",
    "        output = result.stdout.strip()\n",
    "        topics.append(output if output else \"Topic: ERROR_EMPTY_OUTPUT\")\n",
    "\n",
    "    except Exception as e:\n",
    "        topics.append(f\"Topic: ERROR {str(e)}\")\n",
    "\n",
    "# initialize column to prevent length mismatch\n",
    "df[\"topic_highlight\"] = None\n",
    "\n",
    "# assign to first 100 rows only\n",
    "df.loc[:99, \"topic_highlight\"] = topics\n",
    "\n",
    "df.to_csv(\"topic_highlighted_speeches.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Done. File saved as topic_highlighted_speeches.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2c73017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 100 enhanced speeches ‚Üí enhanced_speeches_sample.csv\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.head(100).copy()\n",
    "df_sample[\"enhanced_speech\"] = topics\n",
    "df_sample.to_csv(\"enhanced_speeches_sample.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Saved 100 enhanced speeches ‚Üí enhanced_speeches_sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75c841fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Speeches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [01:16<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Random 100 speech topic classification complete.\n",
      "File saved as topic_highlighted_100_random.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[df[\"speech\"].apply(lambda x: len(str(x).split()) > 30)]\n",
    "\n",
    "# Take random 100 rows\n",
    "df_sample = df_filtered.sample(100, random_state=42).copy()\n",
    "\n",
    "BASE_PROMPT = \"\"\"\n",
    "You are an expert Indian Parliamentary proceedings topic classifier. \n",
    "Your job is NOT to summarize the speech. Your job is to identify what specific policy / issue / subject matter is being talked about in ONE short crisp category.\n",
    "\n",
    "Rules:\n",
    "- Return EXACTLY 1 topic phrase for each speech (7-12 words max)\n",
    "- If the speech is just procedural / rhetorical / filler / greeting ‚Üí return \"irrelevant\"\n",
    "- Hindi, English, Hinglish all supported.\n",
    "- Make topics focused on meaning, not literal words.\n",
    "\n",
    "FORMAT:\n",
    "Topic: <short topic phrase>\n",
    "\n",
    "### Example:\n",
    "Speech Input:\n",
    "\"National Commission for Religious and Linguistic Minorities‚Ä¶ Dalit Christians and Dalit Muslims reservations extension‚Ä¶\"\n",
    "\n",
    "Output:\n",
    "Topic: Reservation for Dalit Christians and Dalit Muslims\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "topics = []\n",
    "\n",
    "for speech in tqdm(df_sample[\"speech\"], desc=\"Processing Speeches\"):\n",
    "    prompt = BASE_PROMPT + f\"\\n\\nSpeech Input:\\n{speech}\\n\\nOutput:\\n\"\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"llama3.2\"],\n",
    "            input=prompt,\n",
    "            text=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "\n",
    "        output = result.stdout.strip()\n",
    "        topics.append(output if output else \"Topic: ERROR_EMPTY_OUTPUT\")\n",
    "\n",
    "    except Exception as e:\n",
    "        topics.append(f\"Topic: ERROR {str(e)}\")\n",
    "\n",
    "\n",
    "df_sample[\"topic_highlight\"] = topics\n",
    "df_sample.to_csv(\"topic_highlighted_100_random.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Random 100 speech topic classification complete.\")\n",
    "print(\"File saved as topic_highlighted_100_random.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dba10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_env)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
